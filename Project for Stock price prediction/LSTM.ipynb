{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import xgboost as xgb #Gradient boosting\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel #model selection\n",
    "from sklearn.metrics import accuracy_score #model testing\n",
    "import matplotlib.mlab as mlab  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import decomposition\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for intraday price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/dingding/Desktop/GIII_3minutenew.csv')\n",
    "data=data.drop(data.index[[0,1,2,3]])\n",
    "null_columns=data.columns[data.isnull().any()]\n",
    "data[null_columns].isnull().sum()\n",
    "data=data.dropna(subset = ['MFI_3', 'Donchian_3'])\n",
    "features=data.iloc[:,2:-2]\n",
    "labels=data.iloc[:,-1]\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(np_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epochs: 10,50,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3115  754]\n",
      " [ 830 3526]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.79      0.81      0.80      3869\n",
      "          1       0.82      0.81      0.82      4356\n",
      "\n",
      "avg / total       0.81      0.81      0.81      8225\n",
      "\n",
      "0.8074164133738602\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3123  746]\n",
      " [ 541 3815]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.81      0.83      3869\n",
      "          1       0.84      0.88      0.86      4356\n",
      "\n",
      "avg / total       0.84      0.84      0.84      8225\n",
      "\n",
      "0.8435258358662614\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3249  620]\n",
      " [ 601 3755]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.84      0.84      3869\n",
      "          1       0.86      0.86      0.86      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8515501519756838\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Activation Function: linear softmax, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3119  750]\n",
      " [ 489 3867]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.81      0.83      3869\n",
      "          1       0.84      0.89      0.86      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8493617021276596\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='linear'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3073  796]\n",
      " [ 634 3722]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      0.79      0.81      3869\n",
      "          1       0.82      0.85      0.84      4356\n",
      "\n",
      "avg / total       0.83      0.83      0.83      8225\n",
      "\n",
      "0.8261398176291793\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform',activation='sigmoid'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2956  913]\n",
      " [ 570 3786]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.76      0.80      3869\n",
      "          1       0.81      0.87      0.84      4356\n",
      "\n",
      "avg / total       0.82      0.82      0.82      8225\n",
      "\n",
      "0.8196960486322189\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform',activation='softmax'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2990  879]\n",
      " [ 343 4013]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.90      0.77      0.83      3869\n",
      "          1       0.82      0.92      0.87      4356\n",
      "\n",
      "avg / total       0.86      0.85      0.85      8225\n",
      "\n",
      "0.8514285714285714\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform',activation='tanh'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Dropout Regularization 0.0,0.1,.0.2,0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3244  625]\n",
      " [ 581 3775]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.84      0.84      3869\n",
      "          1       0.86      0.87      0.86      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8533738601823708\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.0))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "# summarize results\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3244  625]\n",
      " [ 581 3775]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.84      0.84      3869\n",
      "          1       0.86      0.87      0.86      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8533738601823708\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model1():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model1= KerasClassifier(build_fn=create_model1, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model1.fit(X_train, y_train)\n",
    "# summarize results\n",
    "pre1=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre1))  \n",
    "print(classification_report(y_test, pre1)) \n",
    "print (accuracy_score(y_test, pre1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3424  445]\n",
      " [ 798 3558]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.88      0.85      3869\n",
      "          1       0.89      0.82      0.85      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8488753799392097\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "# summarize results\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3490  379]\n",
      " [ 887 3469]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      0.90      0.85      3869\n",
      "          1       0.90      0.80      0.85      4356\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8460790273556231\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model(neurons=25):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "# summarize results\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3567  302]\n",
      " [1117 3239]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.76      0.92      0.83      3869\n",
      "          1       0.91      0.74      0.82      4356\n",
      "\n",
      "avg / total       0.84      0.83      0.83      8225\n",
      "\n",
      "0.8274772036474164\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model(neurons=30):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_train, y_train)\n",
    "# summarize results\n",
    "pre=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pre))  \n",
    "print(classification_report(y_test, pre)) \n",
    "print (accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM daily price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data=pd.read_csv('/Users/dingding/Desktop/GIIIUS_daily_new.csv')\n",
    "null_columns=daily_data.columns[daily_data.isnull().any()]\n",
    "daily_data[null_columns].isnull().sum()\n",
    "daily_data=daily_data.dropna(subset = ['Donchian_3'])\n",
    "daily_data=daily_data.drop(['field','RETURN_COM_EQY','EBITDA','IS_EPS','PROF_MARGIN','ROC_3','Return_3','return/ebitda','return/EPS','return/pro','return/ROE'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_features=daily_data.iloc[:,0:-1]\n",
    "daily_labels=daily_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(daily_features)\n",
    "dailyfeatures_normalized = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dailytrain, X_dailytest, y_dailytrain, y_dailytest = train_test_split(dailyfeatures_normalized, daily_labels, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epochs: 10,50,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[463 139]\n",
      " [180 536]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.77      0.74       602\n",
      "          1       0.79      0.75      0.77       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "0.7579666160849773\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[450 152]\n",
      " [171 545]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.75      0.74       602\n",
      "          1       0.78      0.76      0.77       716\n",
      "\n",
      "avg / total       0.76      0.75      0.76      1318\n",
      "\n",
      "0.7549317147192717\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[458 144]\n",
      " [175 541]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.76      0.74       602\n",
      "          1       0.79      0.76      0.77       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "0.7579666160849773\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Activation Function: linear softmax, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[441 161]\n",
      " [167 549]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.73      0.73       602\n",
      "          1       0.77      0.77      0.77       716\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1318\n",
      "\n",
      "0.7511380880121397\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='linear'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[457 145]\n",
      " [176 540]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.76      0.74       602\n",
      "          1       0.79      0.75      0.77       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "0.7564491654021245\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='sigmoid'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[424 178]\n",
      " [151 565]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.70      0.72       602\n",
      "          1       0.76      0.79      0.77       716\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1318\n",
      "\n",
      "0.7503793626707133\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='softmax'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Dropout Regularization 0.0,0.1,.0.2,0.3Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[423 179]\n",
      " [152 564]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.70      0.72       602\n",
      "          1       0.76      0.79      0.77       716\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1318\n",
      "\n",
      "0.7488619119878603\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='sigmoid', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.0))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[461 141]\n",
      " [176 540]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.77      0.74       602\n",
      "          1       0.79      0.75      0.77       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "0.7594840667678301\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='sigmoid', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[439 163]\n",
      " [158 558]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.73      0.73       602\n",
      "          1       0.77      0.78      0.78       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='sigmoid', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[441 161]\n",
      " [158 558]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.73      0.73       602\n",
      "          1       0.78      0.78      0.78       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.73      0.73       602\n",
      "          1       0.78      0.78      0.78       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='sigmoid', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[456 146]\n",
      " [174 542]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.76      0.74       602\n",
      "          1       0.79      0.76      0.77       716\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1318\n",
      "\n",
      "0.7572078907435509\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(30, input_dim=X_dailytrain.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_dailytrain, y_dailytrain)\n",
    "pre_daily=model.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, pre_daily))  \n",
    "print(classification_report(y_dailytest, pre_daily)) \n",
    "print (accuracy_score(y_dailytest, pre_daily))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM miunte data with feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_feature=data.drop(['time','high','low','volume','MA_3','Momentum_3','RSI_3','MFI_3','Donchian_3'],axis = 1)\n",
    "features_importance=data_feature.iloc[:,2:-1]\n",
    "\n",
    "labels_importance=data_feature.iloc[:,-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(features_importance)\n",
    "featuresimport_normalized = pd.DataFrame(np_scaled)\n",
    "\n",
    "X_impor, X_impor_test, y_impor, y_impor_test = train_test_split(featuresimport_normalized, labels_importance, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3062  792]\n",
      " [ 438 3933]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.79      0.83      3854\n",
      "          1       0.83      0.90      0.86      4371\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8504559270516717\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_impor.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_impor, y_impor)\n",
    "pre=model.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, pre))  \n",
    "print(classification_report(y_impor_test, pre)) \n",
    "print (accuracy_score(y_impor_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3842   12]\n",
      " [ 225 4146]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      1.00      0.97      3854\n",
      "          1       1.00      0.95      0.97      4371\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8225\n",
      "\n",
      "0.9711854103343465\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_impor.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_impor, y_impor)\n",
    "pre=model.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, pre))  \n",
    "print(classification_report(y_impor_test, pre)) \n",
    "print (accuracy_score(y_impor_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3712  142]\n",
      " [   4 4367]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.96      0.98      3854\n",
      "          1       0.97      1.00      0.98      4371\n",
      "\n",
      "avg / total       0.98      0.98      0.98      8225\n",
      "\n",
      "0.9822492401215805\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=X_impor.shape[1], kernel_initializer='uniform'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_impor, y_impor)\n",
    "pre=model.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, pre))  \n",
    "print(classification_report(y_impor_test, pre)) \n",
    "print (accuracy_score(y_impor_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3841   33]\n",
      " [  39 4312]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.99      0.99      0.99      3874\n",
      "          1       0.99      0.99      0.99      4351\n",
      "\n",
      "avg / total       0.99      0.99      0.99      8225\n",
      "\n",
      "0.9912462006079027\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model(neurons=1):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_dim=X_impor.shape[1], kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(X_impor, y_impor)\n",
    "pre=model.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, pre))  \n",
    "print(classification_report(y_impor_test, pre)) \n",
    "print (accuracy_score(y_impor_test, pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for daily with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data=pd.read_csv('/Users/dingding/Desktop/GIIIUS_daily_new.csv')\n",
    "null_columns=daily_data.columns[daily_data.isnull().any()]\n",
    "daily_data[null_columns].isnull().sum()\n",
    "daily_data=daily_data.dropna(subset = ['Donchian_3'])\n",
    "daily_data_impor=daily_data.drop(['field','close','low','open','volume','CUR_MKT_CAP','PE_RATIO','RETURN_COM_EQY','EBITDA','IS_EPS','PROF_MARGIN','ROC_3','Return_3',\n",
    "                                 'RSI_3','MFI_3','OBV_3','STD_3','Donchian_3','cap/ebitda','close/ebitda','cap/EPS','close/EPS',\n",
    "                                'close/pro','return/ebitda','return/EPS','return/pro','return/ROE'],axis = 1)\n",
    "daily_features_impor=daily_data_impor.iloc[:,0:-1]\n",
    "daily_labels_impor=daily_data_impor.iloc[:,-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(daily_features_impor)\n",
    "daily_featuresimport_normalized = pd.DataFrame(np_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdaily_impor, Xdaily_impor_test, ydaily_impor, ydaily_impor_test = train_test_split(daily_featuresimport_normalized, daily_labels_impor, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[440 186]\n",
      " [141 551]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.76      0.70      0.73       626\n",
      "          1       0.75      0.80      0.77       692\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1318\n",
      "\n",
      "0.7518968133535661\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "def create_model(neurons=30):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_dim=Xdaily_impor.shape[1], kernel_initializer='uniform', activation='tanh', kernel_constraint=maxnorm(4)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "model.fit(Xdaily_impor, ydaily_impor)\n",
    "pre=model.predict(Xdaily_impor_test)\n",
    "print(confusion_matrix(ydaily_impor_test, pre))  \n",
    "print(classification_report(ydaily_impor_test, pre)) \n",
    "print (accuracy_score(ydaily_impor_test, pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
