{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import xgboost as xgb #Gradient boosting\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel #model selection\n",
    "from sklearn.metrics import accuracy_score #model testing\n",
    "import matplotlib.mlab as mlab  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model for minute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/dingding/Desktop/GIII_3minutenew.csv')\n",
    "data=data.drop(data.index[[0,1,2,3]])\n",
    "\n",
    "null_columns=data.columns[data.isnull().any()]\n",
    "data[null_columns].isnull().sum()\n",
    "data=data.dropna(subset = ['MFI_3', 'Donchian_3'])\n",
    "features=data.iloc[:,2:-2]\n",
    "labels=data.iloc[:,-1]\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "y_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.96812, std: 0.00184, params: {'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 3},\n",
       "  mean: 0.97048, std: 0.00168, params: {'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 3},\n",
       "  mean: 0.97131, std: 0.00168, params: {'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 3},\n",
       "  mean: 0.96798, std: 0.00194, params: {'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 3},\n",
       "  mean: 0.97020, std: 0.00171, params: {'n_estimators': 1000, 'min_child_weight': 3, 'max_depth': 3},\n",
       "  mean: 0.97106, std: 0.00158, params: {'n_estimators': 1500, 'min_child_weight': 3, 'max_depth': 3},\n",
       "  mean: 0.96820, std: 0.00175, params: {'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 3},\n",
       "  mean: 0.97044, std: 0.00141, params: {'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 3},\n",
       "  mean: 0.97134, std: 0.00151, params: {'n_estimators': 1500, 'min_child_weight': 5, 'max_depth': 3},\n",
       "  mean: 0.97196, std: 0.00142, params: {'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 5},\n",
       "  mean: 0.97280, std: 0.00135, params: {'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 5},\n",
       "  mean: 0.97282, std: 0.00123, params: {'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 5},\n",
       "  mean: 0.97214, std: 0.00164, params: {'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 5},\n",
       "  mean: 0.97259, std: 0.00157, params: {'n_estimators': 1000, 'min_child_weight': 3, 'max_depth': 5},\n",
       "  mean: 0.97250, std: 0.00167, params: {'n_estimators': 1500, 'min_child_weight': 3, 'max_depth': 5},\n",
       "  mean: 0.97211, std: 0.00175, params: {'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 5},\n",
       "  mean: 0.97271, std: 0.00175, params: {'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 5},\n",
       "  mean: 0.97246, std: 0.00174, params: {'n_estimators': 1500, 'min_child_weight': 5, 'max_depth': 5},\n",
       "  mean: 0.97271, std: 0.00136, params: {'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 7},\n",
       "  mean: 0.97287, std: 0.00125, params: {'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 7},\n",
       "  mean: 0.97271, std: 0.00132, params: {'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 7},\n",
       "  mean: 0.97260, std: 0.00166, params: {'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 7},\n",
       "  mean: 0.97279, std: 0.00172, params: {'n_estimators': 1000, 'min_child_weight': 3, 'max_depth': 7},\n",
       "  mean: 0.97258, std: 0.00164, params: {'n_estimators': 1500, 'min_child_weight': 3, 'max_depth': 7},\n",
       "  mean: 0.97277, std: 0.00151, params: {'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 7},\n",
       "  mean: 0.97260, std: 0.00152, params: {'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 7},\n",
       "  mean: 0.97232, std: 0.00163, params: {'n_estimators': 1500, 'min_child_weight': 5, 'max_depth': 7},\n",
       "  mean: 0.97294, std: 0.00143, params: {'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 9},\n",
       "  mean: 0.97289, std: 0.00145, params: {'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 9},\n",
       "  mean: 0.97272, std: 0.00147, params: {'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 9},\n",
       "  mean: 0.97281, std: 0.00165, params: {'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 9},\n",
       "  mean: 0.97281, std: 0.00157, params: {'n_estimators': 1000, 'min_child_weight': 3, 'max_depth': 9},\n",
       "  mean: 0.97250, std: 0.00162, params: {'n_estimators': 1500, 'min_child_weight': 3, 'max_depth': 9},\n",
       "  mean: 0.97283, std: 0.00150, params: {'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 9},\n",
       "  mean: 0.97261, std: 0.00156, params: {'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 9},\n",
       "  mean: 0.97235, std: 0.00154, params: {'n_estimators': 1500, 'min_child_weight': 5, 'max_depth': 9}],\n",
       " {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 500},\n",
       " 0.9729355101126336)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':np.arange(3,10,2),\n",
    " 'min_child_weight':np.arange(1,6,2),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3474  395]\n",
      " [ 422 3934]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.89      0.90      0.89      3869\n",
      "          1       0.91      0.90      0.91      4356\n",
      "\n",
      "avg / total       0.90      0.90      0.90      8225\n",
      "\n",
      "0.9006686930091186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_predicted = gsearch1.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predicted))  \n",
    "print(classification_report(y_test, y_predicted)) \n",
    "print (accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.96132, std: 0.00261, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.96589, std: 0.00220, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.96812, std: 0.00198, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.96132, std: 0.00261, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.96589, std: 0.00220, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.96812, std: 0.00198, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.96132, std: 0.00261, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.96589, std: 0.00220, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.96812, std: 0.00198, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.96468, std: 0.00243, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.96839, std: 0.00202, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.97017, std: 0.00183, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.96468, std: 0.00243, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.96839, std: 0.00202, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.97017, std: 0.00183, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.96468, std: 0.00243, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.96839, std: 0.00202, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.97017, std: 0.00183, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.96592, std: 0.00223, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.96932, std: 0.00194, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.97092, std: 0.00175, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.96592, std: 0.00223, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.96932, std: 0.00194, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.97092, std: 0.00175, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.96592, std: 0.00223, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.96932, std: 0.00194, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.97092, std: 0.00175, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1500}],\n",
       " {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       " 0.97092111552478)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1500,max_depth=9, \n",
    "        min_samples_split=1200, min_samples_leaf=60, subsample=0.85, random_state=10, max_features=7,\n",
    "warm_start=True), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3459  410]\n",
      " [ 428 3928]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.89      0.89      0.89      3869\n",
      "          1       0.91      0.90      0.90      4356\n",
      "\n",
      "avg / total       0.90      0.90      0.90      8225\n",
      "\n",
      "0.8981155015197568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb_predicted = gsearch2.predict(X_test)\n",
    "print(confusion_matrix(y_test, gb_predicted))  \n",
    "print(classification_report(y_test, gb_predicted))  \n",
    "print (accuracy_score(y_test, gb_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.95610, std: 0.00290, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.95601, std: 0.00294, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.95598, std: 0.00292, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.95562, std: 0.00302, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.95570, std: 0.00301, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.95570, std: 0.00295, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.95541, std: 0.00286, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.95536, std: 0.00301, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.95544, std: 0.00290, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.96029, std: 0.00257, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.96022, std: 0.00265, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.96027, std: 0.00260, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.95992, std: 0.00262, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.95992, std: 0.00263, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.95993, std: 0.00265, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.95955, std: 0.00268, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.95959, std: 0.00260, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.95957, std: 0.00267, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.96200, std: 0.00250, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.96201, std: 0.00254, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.96201, std: 0.00248, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.96158, std: 0.00251, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.96167, std: 0.00246, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.96170, std: 0.00255, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.96127, std: 0.00263, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.96133, std: 0.00251, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.96134, std: 0.00253, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1500}],\n",
       " {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       " 0.9620097701214576)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "param_test3 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 10, max_depth=10, min_samples_split=10,max_features=5), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3383  486]\n",
      " [ 476 3880]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.88      0.87      0.88      3869\n",
      "          1       0.89      0.89      0.89      4356\n",
      "\n",
      "avg / total       0.88      0.88      0.88      8225\n",
      "\n",
      "0.8830395136778115\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = gsearch3.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "print(confusion_matrix(y_test, predictions))  \n",
    "print(classification_report(y_test, predictions))  \n",
    "print (accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test12 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch12 = GridSearchCV(estimator = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5), \n",
    "param_grid = param_test12, scoring='roc_auc',n_jobs=4,iid=False, cv=5)   \n",
    "gsearch12.fit(X_train, y_train)\n",
    "gsearch12.grid_scores_, gsearch12.best_params_, gsearch12.best_score_\n",
    "\n",
    "\n",
    "extc_pred = gsearch12.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3239  630]\n",
      " [ 472 3884]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.84      0.85      3869\n",
      "          1       0.86      0.89      0.88      4356\n",
      "\n",
      "avg / total       0.87      0.87      0.87      8225\n",
      "\n",
      "0.8660182370820668\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, extc_pred))  \n",
    "print(classification_report(y_test, extc_pred))  \n",
    "print (accuracy_score(y_test, extc_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model for daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(features_normalized, labels, test_size = 0.20) \n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high               0\n",
       "close              0\n",
       "low                0\n",
       "open               0\n",
       "volume             0\n",
       "CUR_MKT_CAP        0\n",
       "PE_RATIO           0\n",
       "MA_3               0\n",
       "Trix_3             0\n",
       "MACD_1_4           0\n",
       "RSI_3              0\n",
       "MFI_3           1002\n",
       "OBV_3             60\n",
       "Force_3          423\n",
       "STD_3              0\n",
       "Donchian_3        20\n",
       "cap/ebitda         0\n",
       "close/ebitda       0\n",
       "cap/EPS            0\n",
       "close/EPS          0\n",
       "cap/ROE            0\n",
       "close/ROE          0\n",
       "cap/pro            0\n",
       "close/pro          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data=pd.read_csv('/Users/dingding/Desktop/GIIIUS_daily_new.csv')\n",
    "null_columns=daily_data.columns[daily_data.isnull().any()]\n",
    "daily_data[null_columns].isnull().sum()\n",
    "daily_data=daily_data.dropna(subset = ['Donchian_3'])\n",
    "daily_data=daily_data.drop(['field','RETURN_COM_EQY','EBITDA','IS_EPS','PROF_MARGIN','ROC_3','Return_3','return/ebitda','return/EPS','return/pro','return/ROE'],axis = 1)\n",
    "daily_features=daily_data.iloc[:,0:-1]\n",
    "daily_labels=daily_data.iloc[:,-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(daily_features)\n",
    "dailyfeatures_normalized = pd.DataFrame(np_scaled)\n",
    "(daily_features == 0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.94365, std: 0.00281, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94090, std: 0.00244, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.93919, std: 0.00299, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94412, std: 0.00293, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94046, std: 0.00214, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.93877, std: 0.00275, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94284, std: 0.00318, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.94019, std: 0.00283, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.93837, std: 0.00321, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94234, std: 0.00326, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.93999, std: 0.00331, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.93913, std: 0.00321, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94204, std: 0.00330, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.93980, std: 0.00336, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.93884, std: 0.00343, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94210, std: 0.00293, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.93952, std: 0.00275, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.93865, std: 0.00296, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94204, std: 0.00329, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94075, std: 0.00322, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.93997, std: 0.00321, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94063, std: 0.00213, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.93933, std: 0.00225, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.93879, std: 0.00241, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94095, std: 0.00247, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.93929, std: 0.00251, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.93843, std: 0.00267, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94221, std: 0.00307, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94145, std: 0.00335, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.94087, std: 0.00335, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94155, std: 0.00240, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94032, std: 0.00218, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.93950, std: 0.00207, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94082, std: 0.00255, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.93914, std: 0.00274, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.93861, std: 0.00292, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 5}],\n",
       " {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 500},\n",
       " 0.944121469024647)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dailytrain, X_dailytest, y_dailytrain, y_dailytest = train_test_split(dailyfeatures_normalized, daily_labels, test_size = 0.20)  \n",
    "param_test5 = {\n",
    " 'max_depth':np.arange(3,10,2),\n",
    " 'min_child_weight':np.arange(1,6,2),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_dailytrain,y_dailytrain)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_predicted = gsearch5.predict(X_dailytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[502  97]\n",
      " [ 88 631]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.84      0.84       599\n",
      "          1       0.87      0.88      0.87       719\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1318\n",
      "\n",
      "0.8596358118361154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_dailytest, y_predicted))  \n",
    "print(classification_report(y_dailytest, y_predicted)) \n",
    "print (accuracy_score(y_dailytest, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.92901, std: 0.00560, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.93744, std: 0.00483, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94081, std: 0.00411, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.92901, std: 0.00560, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.93744, std: 0.00483, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94081, std: 0.00411, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.92901, std: 0.00560, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.93744, std: 0.00483, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94081, std: 0.00411, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.93536, std: 0.00526, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.94198, std: 0.00406, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94391, std: 0.00359, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.93536, std: 0.00526, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.94198, std: 0.00406, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94391, std: 0.00359, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.93536, std: 0.00526, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.94198, std: 0.00406, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94391, std: 0.00359, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.93777, std: 0.00473, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.94357, std: 0.00354, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94496, std: 0.00296, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.93777, std: 0.00473, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.94357, std: 0.00354, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94496, std: 0.00296, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.93777, std: 0.00473, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.94357, std: 0.00354, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94496, std: 0.00296, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1500}],\n",
       " {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       " 0.9449568876376558)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1500,max_depth=9, \n",
    "        min_samples_split=1200, min_samples_leaf=60, subsample=0.85, random_state=10, max_features=7,\n",
    "warm_start=True), \n",
    "param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_dailytrain,y_dailytrain)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[505  94]\n",
      " [ 78 641]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.84      0.85       599\n",
      "          1       0.87      0.89      0.88       719\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1318\n",
      "\n",
      "0.8694992412746586\n"
     ]
    }
   ],
   "source": [
    "GBpredict = gsearch6.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, GBpredict))  \n",
    "print(classification_report(y_dailytest, GBpredict))  \n",
    "print (accuracy_score(y_dailytest, GBpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "param_test7 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 10, max_depth=10, min_samples_split=10,max_features=5), \n",
    "param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X_dailytrain,y_dailytrain)\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_\n",
    "\n",
    "\n",
    "predict = gsearch7.predict(X_dailytest)\n",
    "# Calculate the absolute errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[497 102]\n",
      " [ 86 633]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.83      0.84       599\n",
      "          1       0.86      0.88      0.87       719\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1318\n",
      "\n",
      "0.8694992412746586\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dailytest, predict))  \n",
    "print(classification_report(y_dailytest, predict))  \n",
    "print (accuracy_score(y_dailytest, GBpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      "[[439 136]\n",
      " [149 594]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.76      0.75       575\n",
      "          1       0.81      0.80      0.81       743\n",
      "\n",
      "avg / total       0.78      0.78      0.78      1318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extc = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5\n",
    "                           )      \n",
    "\n",
    "extc.fit(X_dailytrain, y_dailytrain) \n",
    "\n",
    "print('Predict...')\n",
    "extc_pred = extc.predict(X_dailytest)\n",
    "print(confusion_matrix(y_dailytest, extc_pred))  \n",
    "print(classification_report(y_dailytest, extc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "param_test12 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch12 = GridSearchCV(estimator = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5), \n",
    "param_grid = param_test12, scoring='roc_auc',n_jobs=4,iid=False, cv=5)   \n",
    "gsearch12.fit(X_dailytrain, y_dailytrain)\n",
    "gsearch12.grid_scores_, gsearch12.best_params_, gsearch12.best_score_\n",
    "\n",
    "\n",
    "extc_pred = gsearch12.predict(X_dailytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[466 133]\n",
      " [ 92 627]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.78      0.81       599\n",
      "          1       0.82      0.87      0.85       719\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1318\n",
      "\n",
      "0.8292867981790591\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dailytest, extc_pred))  \n",
    "print(classification_report(y_dailytest, extc_pred))\n",
    "print (accuracy_score(y_dailytest, extc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miunte data with feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature=data.drop(['time','close','high','low','open','volume','MA_3','Force_3'],axis = 1)\n",
    "features_importance=data_feature.iloc[:,2:-2]\n",
    "\n",
    "labels_importance=data_feature.iloc[:,-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(features_importance)\n",
    "featuresimport_normalized = pd.DataFrame(np_scaled)\n",
    "\n",
    "X_impor, X_impor_test, y_impor, y_impor_test = train_test_split(featuresimport_normalized, labels_importance, test_size = 0.20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgbModel= XGBClassifier( learning_rate =0.1, n_estimators=500, max_depth=9,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "xgbModel = xgbModel.fit(X_impor,y_impor)\n",
    " \n",
    "y_predicted = xgbModel.predict(X_impor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3121  728]\n",
      " [ 551 3825]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.81      0.83      3849\n",
      "          1       0.84      0.87      0.86      4376\n",
      "\n",
      "avg / total       0.84      0.84      0.84      8225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_impor_test, y_predicted))  \n",
    "print(classification_report(y_impor_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.005, loss='deviance', max_depth=7,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=60, min_samples_split=50,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
       "              presort='auto', random_state=10, subsample=0.85, verbose=0,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb= GradientBoostingClassifier(learning_rate=0.005, n_estimators=1500,max_depth=7, \n",
    "        min_samples_split=50, min_samples_leaf=60, subsample=0.85, random_state=10, max_features=5,\n",
    "warm_start=True)\n",
    "gb.fit(X_impor,y_impor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3160  698]\n",
      " [ 546 3821]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.82      0.84      3858\n",
      "          1       0.85      0.87      0.86      4367\n",
      "\n",
      "avg / total       0.85      0.85      0.85      8225\n",
      "\n",
      "0.8487537993920973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_gb = gb.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, y_gb))  \n",
    "print(classification_report(y_impor_test, y_gb))\n",
    "print (accuracy_score(y_impor_test, y_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3106  752]\n",
      " [ 578 3789]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.84      0.81      0.82      3858\n",
      "          1       0.83      0.87      0.85      4367\n",
      "\n",
      "avg / total       0.84      0.84      0.84      8225\n",
      "\n",
      "0.8382978723404255\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators = 1000, max_depth=7, min_samples_split=50,max_features=5)\n",
    "rf.fit(X_impor,y_impor)\n",
    "y_rf = rf.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, y_rf))  \n",
    "print(classification_report(y_impor_test, y_rf))\n",
    "print (accuracy_score(y_impor_test, y_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      "[[2984  874]\n",
      " [ 623 3744]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      0.77      0.80      3858\n",
      "          1       0.81      0.86      0.83      4367\n",
      "\n",
      "avg / total       0.82      0.82      0.82      8225\n",
      "\n",
      "0.8179939209726443\n"
     ]
    }
   ],
   "source": [
    "extc = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5\n",
    "                           )      \n",
    "\n",
    "extc.fit(X_impor,y_impor) \n",
    "\n",
    "print('Predict...')\n",
    "extc_pred = extc.predict(X_impor_test)\n",
    "print(confusion_matrix(y_impor_test, extc_pred))  \n",
    "print(classification_report(y_impor_test, extc_pred))\n",
    "print (accuracy_score(y_impor_test, extc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daily data with feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data=pd.read_csv('/Users/dingding/Desktop/GIIIUS_daily_new.csv')\n",
    "null_columns=daily_data.columns[daily_data.isnull().any()]\n",
    "daily_data[null_columns].isnull().sum()\n",
    "daily_data=daily_data.dropna(subset = ['Donchian_3'])\n",
    "daily_data_impor=daily_data.drop(['field','high','close','low','open','volume','CUR_MKT_CAP','PE_RATIO','RETURN_COM_EQY','EBITDA','IS_EPS','PROF_MARGIN','ROC_3','Return_3',\n",
    "                                  'cap/ebitda','close/ebitda','cap/EPS','close/EPS','cap/ROE',\n",
    "                                  'close/ROE','cap/pro','close/pro','return/ebitda','return/EPS','return/pro','return/ROE','MFI_3'],axis = 1)\n",
    "daily_features_impor=daily_data_impor.iloc[:,0:-1]\n",
    "daily_labels_impor=daily_data_impor.iloc[:,-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(daily_features_impor)\n",
    "daily_featuresimport_normalized = pd.DataFrame(np_scaled)\n",
    "\n",
    "Xdaily_impor, Xdaily_impor_test, ydaily_impor, ydaily_impor_test = train_test_split(daily_featuresimport_normalized, daily_labels_impor, test_size = 0.20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.94599, std: 0.00537, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94387, std: 0.00510, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.94275, std: 0.00483, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94606, std: 0.00664, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94401, std: 0.00625, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.94281, std: 0.00650, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94614, std: 0.00679, params: {'max_depth': 3, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.94433, std: 0.00664, params: {'max_depth': 3, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.94323, std: 0.00614, params: {'max_depth': 3, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94658, std: 0.00544, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94504, std: 0.00571, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.94419, std: 0.00586, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94610, std: 0.00576, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94399, std: 0.00614, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.94313, std: 0.00638, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94628, std: 0.00621, params: {'max_depth': 5, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.94436, std: 0.00597, params: {'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.94327, std: 0.00615, params: {'max_depth': 5, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94661, std: 0.00593, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94572, std: 0.00616, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.94527, std: 0.00627, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94612, std: 0.00643, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94475, std: 0.00675, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.94417, std: 0.00662, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94502, std: 0.00661, params: {'max_depth': 7, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.94366, std: 0.00659, params: {'max_depth': 7, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.94299, std: 0.00663, params: {'max_depth': 7, 'n_estimators': 1500, 'min_child_weight': 5},\n",
       "  mean: 0.94679, std: 0.00603, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 1},\n",
       "  mean: 0.94578, std: 0.00613, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 1},\n",
       "  mean: 0.94544, std: 0.00622, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 1},\n",
       "  mean: 0.94471, std: 0.00652, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 3},\n",
       "  mean: 0.94401, std: 0.00657, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 3},\n",
       "  mean: 0.94351, std: 0.00658, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 3},\n",
       "  mean: 0.94569, std: 0.00615, params: {'max_depth': 9, 'n_estimators': 500, 'min_child_weight': 5},\n",
       "  mean: 0.94452, std: 0.00650, params: {'max_depth': 9, 'n_estimators': 1000, 'min_child_weight': 5},\n",
       "  mean: 0.94372, std: 0.00634, params: {'max_depth': 9, 'n_estimators': 1500, 'min_child_weight': 5}],\n",
       " {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 500},\n",
       " 0.9467930365521408)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test9 = {\n",
    " 'max_depth':np.arange(3,10,2),\n",
    " 'min_child_weight':np.arange(1,6,2),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(Xdaily_impor,ydaily_impor)\n",
    "gsearch9.grid_scores_, gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[543  87]\n",
      " [ 78 610]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.86      0.87       630\n",
      "          1       0.88      0.89      0.88       688\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1318\n",
      "\n",
      "0.8748103186646434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingding/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xg_pred = gsearch9.predict(Xdaily_impor_test)\n",
    "print(confusion_matrix(ydaily_impor_test, xg_pred))  \n",
    "print(classification_report(ydaily_impor_test, xg_pred))\n",
    "print (accuracy_score(ydaily_impor_test, xg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.94124, std: 0.00474, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.94640, std: 0.00503, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94827, std: 0.00520, params: {'max_features': 3, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.94124, std: 0.00474, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.94640, std: 0.00503, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94827, std: 0.00520, params: {'max_features': 3, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.94124, std: 0.00474, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.94640, std: 0.00503, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94827, std: 0.00520, params: {'max_features': 3, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.94337, std: 0.00422, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.94748, std: 0.00481, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94893, std: 0.00524, params: {'max_features': 5, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.94337, std: 0.00422, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.94748, std: 0.00481, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94893, std: 0.00524, params: {'max_features': 5, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.94337, std: 0.00422, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.94748, std: 0.00481, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94893, std: 0.00524, params: {'max_features': 5, 'min_samples_split': 70, 'n_estimators': 1500},\n",
       "  mean: 0.94439, std: 0.00414, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 500},\n",
       "  mean: 0.94799, std: 0.00451, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1000},\n",
       "  mean: 0.94895, std: 0.00509, params: {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       "  mean: 0.94439, std: 0.00414, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 500},\n",
       "  mean: 0.94799, std: 0.00451, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1000},\n",
       "  mean: 0.94895, std: 0.00509, params: {'max_features': 7, 'min_samples_split': 60, 'n_estimators': 1500},\n",
       "  mean: 0.94439, std: 0.00414, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 500},\n",
       "  mean: 0.94799, std: 0.00451, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1000},\n",
       "  mean: 0.94895, std: 0.00509, params: {'max_features': 7, 'min_samples_split': 70, 'n_estimators': 1500}],\n",
       " {'max_features': 7, 'min_samples_split': 50, 'n_estimators': 1500},\n",
       " 0.9489478232498427)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test10 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch10 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1500,max_depth=9, \n",
    "        min_samples_split=1200, min_samples_leaf=60, subsample=0.85, random_state=10, max_features=7,\n",
    "warm_start=True), \n",
    "param_grid = param_test10, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch10.fit(Xdaily_impor,ydaily_impor)\n",
    "gsearch10.grid_scores_, gsearch10.best_params_, gsearch10.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[558  72]\n",
      " [ 81 607]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.89      0.88       630\n",
      "          1       0.89      0.88      0.89       688\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1318\n",
      "\n",
      "0.8839150227617603\n"
     ]
    }
   ],
   "source": [
    "g_pred = gsearch10.predict(Xdaily_impor_test)\n",
    "print(confusion_matrix(ydaily_impor_test, g_pred))  \n",
    "print(classification_report(ydaily_impor_test, g_pred))\n",
    "print (accuracy_score(ydaily_impor_test, g_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "param_test11 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch11 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 10, max_depth=10, min_samples_split=10,max_features=5), \n",
    "param_grid = param_test11, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch11.fit(Xdaily_impor,ydaily_impor)\n",
    "gsearch11.grid_scores_, gsearch11.best_params_, gsearch11.best_score_\n",
    "\n",
    "\n",
    "predict = gsearch11.predict(Xdaily_impor_test)\n",
    "# Calculate the absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[548  82]\n",
      " [ 79 609]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.87      0.87      0.87       630\n",
      "          1       0.88      0.89      0.88       688\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1318\n",
      "\n",
      "0.877845220030349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(ydaily_impor_test, predict))  \n",
    "print(classification_report(ydaily_impor_test, predict))\n",
    "print (accuracy_score(ydaily_impor_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      "[[437 193]\n",
      " [ 78 610]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.69      0.76       630\n",
      "          1       0.76      0.89      0.82       688\n",
      "\n",
      "avg / total       0.80      0.79      0.79      1318\n",
      "\n",
      "0.7943854324734446\n"
     ]
    }
   ],
   "source": [
    "extc = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5\n",
    "                           )      \n",
    "\n",
    "extc.fit(Xdaily_impor,ydaily_impor) \n",
    "\n",
    "print('Predict...')\n",
    "extc_pred = extc.predict(Xdaily_impor_test)\n",
    "print(confusion_matrix(ydaily_impor_test, extc_pred))  \n",
    "print(classification_report(ydaily_impor_test, extc_pred))\n",
    "print (accuracy_score(ydaily_impor_test, extc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      "[[443 187]\n",
      " [ 74 614]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.70      0.77       630\n",
      "          1       0.77      0.89      0.82       688\n",
      "\n",
      "avg / total       0.81      0.80      0.80      1318\n",
      "\n",
      "0.8019726858877086\n"
     ]
    }
   ],
   "source": [
    "extc = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5\n",
    "                           )      \n",
    "\n",
    "extc.fit(Xdaily_impor,ydaily_impor) \n",
    "\n",
    "print('Predict...')\n",
    "extc_pred = extc.predict(Xdaily_impor_test)\n",
    "print(confusion_matrix(ydaily_impor_test, extc_pred))  \n",
    "print(classification_report(ydaily_impor_test, extc_pred))\n",
    "print (accuracy_score(ydaily_impor_test, extc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "param_test12 = {\n",
    " 'max_features':np.arange(3,9,2),\n",
    " 'min_samples_split':np.arange(50,80,10),\n",
    "    'n_estimators':np.arange(500,1600,500)\n",
    "}\n",
    "gsearch12 = GridSearchCV(estimator = ExtraTreesClassifier(n_estimators=5,criterion= 'entropy',min_samples_split= 5,\n",
    "                            max_depth= 50, min_samples_leaf=5), \n",
    "param_grid = param_test12, scoring='roc_auc',n_jobs=4,iid=False, cv=5)   \n",
    "gsearch12.fit(Xdaily_impor,ydaily_impor)\n",
    "gsearch12.grid_scores_, gsearch12.best_params_, gsearch12.best_score_\n",
    "\n",
    "\n",
    "extc_pred = gsearch12.predict(Xdaily_impor_test)\n",
    "# Calculate the absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[499 131]\n",
      " [ 68 620]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.88      0.79      0.83       630\n",
      "          1       0.83      0.90      0.86       688\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1318\n",
      "\n",
      "0.8490136570561456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(ydaily_impor_test, extc_pred))  \n",
    "print(classification_report(ydaily_impor_test, extc_pred))\n",
    "print (accuracy_score(ydaily_impor_test, extc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
